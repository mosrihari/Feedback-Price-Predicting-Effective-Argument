{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c0a121",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-10T04:51:38.554924Z",
     "iopub.status.busy": "2022-08-10T04:51:38.554462Z",
     "iopub.status.idle": "2022-08-10T04:51:45.754348Z",
     "shell.execute_reply": "2022-08-10T04:51:45.753376Z"
    },
    "papermill": {
     "duration": 7.21297,
     "end_time": "2022-08-10T04:51:45.757929",
     "exception": false,
     "start_time": "2022-08-10T04:51:38.544959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizers.__version__: 0.12.1\n",
      "transformers.__version__: 4.20.1\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import re\n",
    "import os\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, DebertaTokenizer, BertTokenizer, TFAutoModel\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from text_unidecode import unidecode\n",
    "from typing import Dict, List, Tuple\n",
    "import codecs\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f89f9afe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:51:45.773329Z",
     "iopub.status.busy": "2022-08-10T04:51:45.772849Z",
     "iopub.status.idle": "2022-08-10T04:51:45.785470Z",
     "shell.execute_reply": "2022-08-10T04:51:45.784183Z"
    },
    "papermill": {
     "duration": 0.022303,
     "end_time": "2022-08-10T04:51:45.787499",
     "exception": false,
     "start_time": "2022-08-10T04:51:45.765196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "    \n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a9f946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:51:45.801816Z",
     "iopub.status.busy": "2022-08-10T04:51:45.801539Z",
     "iopub.status.idle": "2022-08-10T04:51:45.805434Z",
     "shell.execute_reply": "2022-08-10T04:51:45.804553Z"
    },
    "papermill": {
     "duration": 0.013233,
     "end_time": "2022-08-10T04:51:45.807365",
     "exception": false,
     "start_time": "2022-08-10T04:51:45.794132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_DIR = \"../input/feedback-prize-effectiveness\"\n",
    "TRAIN_FOLDS_DIR = '../input/feedbacktrainfolds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25801937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:51:45.822000Z",
     "iopub.status.busy": "2022-08-10T04:51:45.821451Z",
     "iopub.status.idle": "2022-08-10T04:51:46.111499Z",
     "shell.execute_reply": "2022-08-10T04:51:46.110556Z"
    },
    "papermill": {
     "duration": 0.30021,
     "end_time": "2022-08-10T04:51:46.114200",
     "exception": false,
     "start_time": "2022-08-10T04:51:45.813990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{TRAIN_FOLDS_DIR}/train_folds.csv\")\n",
    "test = pd.read_csv(f\"{TEST_DIR}/test.csv\")\n",
    "submission = pd.read_csv(f\"{TEST_DIR}/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4c5c24a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:51:46.129372Z",
     "iopub.status.busy": "2022-08-10T04:51:46.129074Z",
     "iopub.status.idle": "2022-08-10T04:51:46.133968Z",
     "shell.execute_reply": "2022-08-10T04:51:46.133043Z"
    },
    "papermill": {
     "duration": 0.014574,
     "end_time": "2022-08-10T04:51:46.135938",
     "exception": false,
     "start_time": "2022-08-10T04:51:46.121364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_essay_text(essay_id, directory):\n",
    "    parent_path = TEST_DIR + \"/\" + directory\n",
    "    essay_path = os.path.join(parent_path, f\"{essay_id}.txt\")\n",
    "    essay_text = open(essay_path, 'r').read()\n",
    "    return essay_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ec62a48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:51:46.150283Z",
     "iopub.status.busy": "2022-08-10T04:51:46.150025Z",
     "iopub.status.idle": "2022-08-10T04:52:12.405692Z",
     "shell.execute_reply": "2022-08-10T04:52:12.404697Z"
    },
    "papermill": {
     "duration": 26.265628,
     "end_time": "2022-08-10T04:52:12.408192",
     "exception": false,
     "start_time": "2022-08-10T04:51:46.142564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['essay_text'] = train['essay_id'].apply(get_essay_text, directory='train')\n",
    "test['essay_text'] = test['essay_id'].apply(get_essay_text, directory='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63e146ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:12.423817Z",
     "iopub.status.busy": "2022-08-10T04:52:12.423483Z",
     "iopub.status.idle": "2022-08-10T04:52:36.767476Z",
     "shell.execute_reply": "2022-08-10T04:52:36.766202Z"
    },
    "papermill": {
     "duration": 24.355175,
     "end_time": "2022-08-10T04:52:36.770742",
     "exception": false,
     "start_time": "2022-08-10T04:52:12.415567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_encoding_with_utf8(error: UnicodeError) -> Tuple[bytes, int]:\n",
    "    return error.object[error.start : error.end].encode(\"utf-8\"), error.end\n",
    "\n",
    "\n",
    "def replace_decoding_with_cp1252(error: UnicodeError) -> Tuple[str, int]:\n",
    "    return error.object[error.start : error.end].decode(\"cp1252\"), error.end\n",
    "\n",
    "# Register the encoding and decoding error handlers for `utf-8` and `cp1252`.\n",
    "codecs.register_error(\"replace_encoding_with_utf8\", replace_encoding_with_utf8)\n",
    "codecs.register_error(\"replace_decoding_with_cp1252\", replace_decoding_with_cp1252)\n",
    "\n",
    "def resolve_encodings_and_normalize(text: str) -> str:\n",
    "    \"\"\"Resolve the encoding problems and normalize the abnormal characters.\"\"\"\n",
    "    text = (\n",
    "        text.encode(\"raw_unicode_escape\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "        .encode(\"cp1252\", errors=\"replace_encoding_with_utf8\")\n",
    "        .decode(\"utf-8\", errors=\"replace_decoding_with_cp1252\")\n",
    "    )\n",
    "    text = unidecode(text)\n",
    "    return text\n",
    "\n",
    "train['discourse_text'] = train['discourse_text'].apply(resolve_encodings_and_normalize)\n",
    "train['essay_text'] = train['essay_text'].apply(resolve_encodings_and_normalize)\n",
    "\n",
    "test['discourse_text'] = test['discourse_text'].apply(resolve_encodings_and_normalize)\n",
    "test['essay_text'] = test['essay_text'].apply(resolve_encodings_and_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ec4c2ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:36.798753Z",
     "iopub.status.busy": "2022-08-10T04:52:36.798299Z",
     "iopub.status.idle": "2022-08-10T04:52:36.869339Z",
     "shell.execute_reply": "2022-08-10T04:52:36.868404Z"
    },
    "papermill": {
     "duration": 0.083695,
     "end_time": "2022-08-10T04:52:36.871718",
     "exception": false,
     "start_time": "2022-08-10T04:52:36.788023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['text'] = train['discourse_type'] + \" [SEP] \" + train['discourse_text'] + \" [SEP] \" + train['essay_text']\n",
    "test['text'] = test['discourse_type'] + \" [SEP] \" + test['discourse_text'] + \" [SEP] \" + test['essay_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f18e68",
   "metadata": {
    "papermill": {
     "duration": 0.007507,
     "end_time": "2022-08-10T04:52:36.886199",
     "exception": false,
     "start_time": "2022-08-10T04:52:36.878692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bbbdb76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:36.900727Z",
     "iopub.status.busy": "2022-08-10T04:52:36.900397Z",
     "iopub.status.idle": "2022-08-10T04:52:36.914031Z",
     "shell.execute_reply": "2022-08-10T04:52:36.913196Z"
    },
    "papermill": {
     "duration": 0.023153,
     "end_time": "2022-08-10T04:52:36.916037",
     "exception": false,
     "start_time": "2022-08-10T04:52:36.892884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_mapping = {\"Adequate\":0, \"Effective\":1, \"Ineffective\":2}\n",
    "train['discourse_effectiveness'] = train['discourse_effectiveness'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2db93b29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:36.931219Z",
     "iopub.status.busy": "2022-08-10T04:52:36.930680Z",
     "iopub.status.idle": "2022-08-10T04:52:36.940631Z",
     "shell.execute_reply": "2022-08-10T04:52:36.939776Z"
    },
    "papermill": {
     "duration": 0.019514,
     "end_time": "2022-08-10T04:52:36.942639",
     "exception": false,
     "start_time": "2022-08-10T04:52:36.923125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20977\n",
       "1     9326\n",
       "2     6462\n",
       "Name: discourse_effectiveness, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['discourse_effectiveness'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9447043",
   "metadata": {
    "papermill": {
     "duration": 0.006931,
     "end_time": "2022-08-10T04:52:36.956792",
     "exception": false,
     "start_time": "2022-08-10T04:52:36.949861",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "525e95cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:36.971303Z",
     "iopub.status.busy": "2022-08-10T04:52:36.971033Z",
     "iopub.status.idle": "2022-08-10T04:52:37.187396Z",
     "shell.execute_reply": "2022-08-10T04:52:37.186425Z"
    },
    "papermill": {
     "duration": 0.226417,
     "end_time": "2022-08-10T04:52:37.189918",
     "exception": false,
     "start_time": "2022-08-10T04:52:36.963501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../input/robertalarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "897a37ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:37.207006Z",
     "iopub.status.busy": "2022-08-10T04:52:37.206292Z",
     "iopub.status.idle": "2022-08-10T04:52:37.210957Z",
     "shell.execute_reply": "2022-08-10T04:52:37.209940Z"
    },
    "papermill": {
     "duration": 0.015755,
     "end_time": "2022-08-10T04:52:37.213110",
     "exception": false,
     "start_time": "2022-08-10T04:52:37.197355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer.encode_plus(train['text'][0], add_special_tokens=True,\n",
    "#                               padding='max_length',max_length=512).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08af75b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:37.228199Z",
     "iopub.status.busy": "2022-08-10T04:52:37.227909Z",
     "iopub.status.idle": "2022-08-10T04:52:37.232239Z",
     "shell.execute_reply": "2022-08-10T04:52:37.231264Z"
    },
    "papermill": {
     "duration": 0.014345,
     "end_time": "2022-08-10T04:52:37.234255",
     "exception": false,
     "start_time": "2022-08-10T04:52:37.219910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def tokenizer_encode(texts, tokenizer):\n",
    "    \n",
    "#     input_ids = np.zeros((train.shape[0], 512))\n",
    "#     attention_mask_ids = np.zeros((train.shape[0], 512))\n",
    "    \n",
    "#     for e,text in enumerate(texts):\n",
    "#         tokenized_text = tokenizer.encode_plus(text, add_special_tokens=True,\n",
    "#                               padding='max_length',max_length=512,truncation= True)\n",
    "#         input_ids[e,:] = tokenized_text['input_ids']\n",
    "#         attention_mask_ids[e,:] = tokenized_text['attention_mask']\n",
    "\n",
    "#     return input_ids, attention_mask_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09edcf48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:37.249630Z",
     "iopub.status.busy": "2022-08-10T04:52:37.248761Z",
     "iopub.status.idle": "2022-08-10T04:52:37.253259Z",
     "shell.execute_reply": "2022-08-10T04:52:37.252417Z"
    },
    "papermill": {
     "duration": 0.014155,
     "end_time": "2022-08-10T04:52:37.255225",
     "exception": false,
     "start_time": "2022-08-10T04:52:37.241070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X_train = tokenizer_encode(train['text'].astype(str), tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38f9e196",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:37.270244Z",
     "iopub.status.busy": "2022-08-10T04:52:37.269556Z",
     "iopub.status.idle": "2022-08-10T04:52:37.274245Z",
     "shell.execute_reply": "2022-08-10T04:52:37.273398Z"
    },
    "papermill": {
     "duration": 0.014192,
     "end_time": "2022-08-10T04:52:37.276205",
     "exception": false,
     "start_time": "2022-08-10T04:52:37.262013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "975dade8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:37.291359Z",
     "iopub.status.busy": "2022-08-10T04:52:37.291104Z",
     "iopub.status.idle": "2022-08-10T04:52:37.295355Z",
     "shell.execute_reply": "2022-08-10T04:52:37.294395Z"
    },
    "papermill": {
     "duration": 0.013936,
     "end_time": "2022-08-10T04:52:37.297277",
     "exception": false,
     "start_time": "2022-08-10T04:52:37.283341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def build_model(fold, roberta_model, max_len=512):  \n",
    "#     callbacks = tf.keras.callbacks.ModelCheckpoint(f'./roberta{fold}_weights.h5',\n",
    "#                                                    save_weights_only=True, save_best_only=True)\n",
    "#     input_ids = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "#     attention_mask = tf.keras.layers.Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "#     sequence_output = roberta_model(input_ids, attention_mask=attention_mask)[0]\n",
    "#     clf_output = sequence_output[:, 0, :]\n",
    "#     clf_output = tf.keras.layers.Dropout(.1)(clf_output)\n",
    "#     out = tf.keras.layers.Dense(3, activation='softmax')(clf_output)\n",
    "    \n",
    "#     model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=out)\n",
    "#     model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "#     return model, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1364f9aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:37.312008Z",
     "iopub.status.busy": "2022-08-10T04:52:37.311743Z",
     "iopub.status.idle": "2022-08-10T04:52:37.315229Z",
     "shell.execute_reply": "2022-08-10T04:52:37.314305Z"
    },
    "papermill": {
     "duration": 0.013112,
     "end_time": "2022-08-10T04:52:37.317191",
     "exception": false,
     "start_time": "2022-08-10T04:52:37.304079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# roberta_model = (transformers.TFAutoModel.from_pretrained('../input/robertalarge',from_pt=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3255d382",
   "metadata": {
    "papermill": {
     "duration": 0.006703,
     "end_time": "2022-08-10T04:52:37.330796",
     "exception": false,
     "start_time": "2022-08-10T04:52:37.324093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fef88aa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:37.346912Z",
     "iopub.status.busy": "2022-08-10T04:52:37.346033Z",
     "iopub.status.idle": "2022-08-10T04:52:37.351732Z",
     "shell.execute_reply": "2022-08-10T04:52:37.350927Z"
    },
    "papermill": {
     "duration": 0.0161,
     "end_time": "2022-08-10T04:52:37.353997",
     "exception": false,
     "start_time": "2022-08-10T04:52:37.337897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def map_function(encodings , target):\n",
    "    input_ids = encodings['input_ids']\n",
    "    attention_mask = encodings['attention_mask']\n",
    "    \n",
    "    target = tf.cast(target, tf.int8)\n",
    "    \n",
    "    return {'input_ids': input_ids , 'attention_mask': attention_mask}, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8a825d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:37.370093Z",
     "iopub.status.busy": "2022-08-10T04:52:37.369316Z",
     "iopub.status.idle": "2022-08-10T04:52:37.376361Z",
     "shell.execute_reply": "2022-08-10T04:52:37.375512Z"
    },
    "papermill": {
     "duration": 0.017182,
     "end_time": "2022-08-10T04:52:37.378496",
     "exception": false,
     "start_time": "2022-08-10T04:52:37.361314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_id = tf.keras.layers.Input(shape = (512) , dtype = tf.int32, name = 'input_ids')\n",
    "    attention_mask = tf.keras.layers.Input(shape = (512), dtype = tf.int32, name = 'attention_mask')\n",
    "    \n",
    "    transformer_model = transformers.TFAutoModel.from_pretrained('../input/robertalarge', from_pt=True)\n",
    "    cls_token = transformer_model(input_ids = input_id , attention_mask = attention_mask)[0][:,0,:]\n",
    "    \n",
    "    prediction = tf.keras.layers.Dense(3 , activation = \"softmax\")(cls_token)\n",
    "\n",
    "    return tf.keras.models.Model(inputs = [input_id, attention_mask] , outputs = prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ed87de9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:37.394581Z",
     "iopub.status.busy": "2022-08-10T04:52:37.393898Z",
     "iopub.status.idle": "2022-08-10T04:52:37.398446Z",
     "shell.execute_reply": "2022-08-10T04:52:37.397495Z"
    },
    "papermill": {
     "duration": 0.014705,
     "end_time": "2022-08-10T04:52:37.400460",
     "exception": false,
     "start_time": "2022-08-10T04:52:37.385755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "def competition_metrics(y_true, y_preds):\n",
    "    return log_loss(y_true, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "71fbc073",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:37.416726Z",
     "iopub.status.busy": "2022-08-10T04:52:37.415914Z",
     "iopub.status.idle": "2022-08-10T04:52:38.293371Z",
     "shell.execute_reply": "2022-08-10T04:52:38.292414Z"
    },
    "papermill": {
     "duration": 0.888187,
     "end_time": "2022-08-10T04:52:38.296017",
     "exception": false,
     "start_time": "2022-08-10T04:52:37.407830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3eac717e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:38.312213Z",
     "iopub.status.busy": "2022-08-10T04:52:38.311603Z",
     "iopub.status.idle": "2022-08-10T04:52:38.327148Z",
     "shell.execute_reply": "2022-08-10T04:52:38.326223Z"
    },
    "papermill": {
     "duration": 0.025854,
     "end_time": "2022-08-10T04:52:38.329118",
     "exception": false,
     "start_time": "2022-08-10T04:52:38.303264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac28c52e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:38.344495Z",
     "iopub.status.busy": "2022-08-10T04:52:38.344206Z",
     "iopub.status.idle": "2022-08-10T04:52:38.350171Z",
     "shell.execute_reply": "2022-08-10T04:52:38.349176Z"
    },
    "papermill": {
     "duration": 0.015993,
     "end_time": "2022-08-10T04:52:38.352176",
     "exception": false,
     "start_time": "2022-08-10T04:52:38.336183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# histories = []\n",
    "# scores = []\n",
    "# for fold in range(4,5):\n",
    "#     print(f\"====== FOLD RUNNING {fold}======\")\n",
    "    \n",
    "#     X_train = df_train.loc[df_train['kfold'] != fold]['text']\n",
    "#     y_train = df_train.loc[df_train['kfold'] != fold]['discourse_effectiveness']\n",
    "    \n",
    "#     X_test = df_train.loc[df_train['kfold'] == fold]['text']\n",
    "#     y_test = df_train.loc[df_train['kfold'] == fold]['discourse_effectiveness']\n",
    "    \n",
    "#     print(\" Train Generating Tokens\")\n",
    "#     train_embeddings = tokenizer(\n",
    "#         X_train.tolist(),\n",
    "#         truncation = True, \n",
    "#         padding = 'max_length',\n",
    "#         max_length =512    \n",
    "#     )\n",
    "    \n",
    "#     print(\" Validation Generating Tokens\")\n",
    "#     validation_embeddings = tokenizer(\n",
    "#         X_test.tolist(),\n",
    "#         truncation = True, \n",
    "#         padding = 'max_length',\n",
    "#         max_length =512  \n",
    "#     )\n",
    "    \n",
    "#     print(\"Train Generating Dataset\")\n",
    "#     train = tf.data.Dataset.from_tensor_slices((train_embeddings , y_train))\n",
    "#     train = (\n",
    "#                 train\n",
    "#                 .map(map_function, num_parallel_calls= AUTO)\n",
    "#                 .batch(24)\n",
    "#                 .prefetch(AUTO)\n",
    "#             )\n",
    "        \n",
    "#     print(\"Validation Generating Dataset\")\n",
    "#     val = tf.data.Dataset.from_tensor_slices((validation_embeddings , y_test))\n",
    "#     val = (\n",
    "#                 val\n",
    "#                 .map(map_function, num_parallel_calls= AUTO)\n",
    "#                 .batch(24)\n",
    "#                 .prefetch(AUTO)\n",
    "#             )\n",
    "    \n",
    "#     #Clearing backend session\n",
    "#     K.clear_session()\n",
    "#     print(\"Backend Cleared\")\n",
    "\n",
    "#     print(\"Model Creation\")\n",
    "#     with strategy.scope():\n",
    "#         model = create_model()\n",
    "#         model.compile(\n",
    "#           optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-5), \n",
    "#           metrics = ['accuracy'],\n",
    "#           loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "#       )    \n",
    "#     early_stopping= tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",min_delta=0,patience=4,verbose=1,mode=\"min\",restore_best_weights=True)\n",
    "#     modelchkpt = tf.keras.callbacks.ModelCheckpoint(f'./roberta{fold}_weights.h5',\n",
    "#                                                    save_weights_only=True, save_best_only=True)\n",
    "#     hist = model.fit(train , validation_data = val , epochs = 12, callbacks = [early_stopping,modelchkpt])\n",
    "    \n",
    "#     # prediction on val\n",
    "#     print(\"prediction on validation data\")\n",
    "#     preds = model.predict(val , verbose = 1)\n",
    "#     score = competition_metrics(y_test.values,preds)\n",
    "#     scores.append(score)\n",
    "#     print(f\"Log Loss for Fold {fold} is {score}\")\n",
    "\n",
    "#     #saving model\n",
    "#     #print(\"saving model\")\n",
    "    \n",
    "#     #localhost_save_option = tf.saved_model.SaveOptions(experimental_io_device=\"/job:localhost\")\n",
    "#     #model.save(f'./model_{fold}', options=localhost_save_option)\n",
    "    \n",
    "#     del model, X_train , y_train, X_test, y_test, val , train , train_embeddings , validation_embeddings\n",
    "\n",
    "#     histories.append(hist)\n",
    "\n",
    "# print(\"the final average Log Loss is \", np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59f9a44a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:38.367877Z",
     "iopub.status.busy": "2022-08-10T04:52:38.366935Z",
     "iopub.status.idle": "2022-08-10T04:52:38.372211Z",
     "shell.execute_reply": "2022-08-10T04:52:38.371209Z"
    },
    "papermill": {
     "duration": 0.015008,
     "end_time": "2022-08-10T04:52:38.374211",
     "exception": false,
     "start_time": "2022-08-10T04:52:38.359203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_mapping = {\"Adequate\":0, \"Effective\":1, \"Ineffective\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a0c554a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:38.389926Z",
     "iopub.status.busy": "2022-08-10T04:52:38.389327Z",
     "iopub.status.idle": "2022-08-10T04:52:38.394312Z",
     "shell.execute_reply": "2022-08-10T04:52:38.393512Z"
    },
    "papermill": {
     "duration": 0.01507,
     "end_time": "2022-08-10T04:52:38.396241",
     "exception": false,
     "start_time": "2022-08-10T04:52:38.381171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebe5e7a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:38.411213Z",
     "iopub.status.busy": "2022-08-10T04:52:38.410468Z",
     "iopub.status.idle": "2022-08-10T04:52:38.415623Z",
     "shell.execute_reply": "2022-08-10T04:52:38.414831Z"
    },
    "papermill": {
     "duration": 0.014564,
     "end_time": "2022-08-10T04:52:38.417559",
     "exception": false,
     "start_time": "2022-08-10T04:52:38.402995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_map_function(encodings):\n",
    "    input_ids = encodings['input_ids']\n",
    "    attention_mask = encodings['attention_mask']\n",
    "    \n",
    "    \n",
    "    return {'input_ids': input_ids , 'attention_mask': attention_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e25c0194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:52:38.432480Z",
     "iopub.status.busy": "2022-08-10T04:52:38.431764Z",
     "iopub.status.idle": "2022-08-10T04:54:41.974768Z",
     "shell.execute_reply": "2022-08-10T04:54:41.973835Z"
    },
    "papermill": {
     "duration": 123.55251,
     "end_time": "2022-08-10T04:54:41.976727",
     "exception": false,
     "start_time": "2022-08-10T04:52:38.424217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== FOLD RUNNING 0======\n",
      " Test Generating Tokens\n",
      "Test Generating Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 04:52:38.541750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 04:52:38.542956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 04:52:38.543691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 04:52:38.544594: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-10 04:52:38.544931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 04:52:38.545633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 04:52:38.546341: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 04:52:43.403891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 04:52:43.404936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 04:52:43.405742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-10 04:52:43.406336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15047 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend Cleared\n",
      "Model Creation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction on test data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-10 04:53:20.589805: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "====== FOLD RUNNING 1======\n",
      " Test Generating Tokens\n",
      "Test Generating Dataset\n",
      "Backend Cleared\n",
      "Model Creation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction on test data\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "====== FOLD RUNNING 2======\n",
      " Test Generating Tokens\n",
      "Test Generating Dataset\n",
      "Backend Cleared\n",
      "Model Creation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction on test data\n",
      "1/1 [==============================] - 6s 6s/step\n",
      "====== FOLD RUNNING 3======\n",
      " Test Generating Tokens\n",
      "Test Generating Dataset\n",
      "Backend Cleared\n",
      "Model Creation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction on test data\n",
      "1/1 [==============================] - 6s 6s/step\n"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "scores = []\n",
    "preds_list = []\n",
    "for fold in range(4):\n",
    "    print(f\"====== FOLD RUNNING {fold}======\")\n",
    "    \n",
    "    X_test = df_test['text']\n",
    "    \n",
    "    print(\" Test Generating Tokens\")\n",
    "    test_embeddings = tokenizer(\n",
    "        X_test.tolist(),\n",
    "        truncation = True, \n",
    "        padding = 'max_length',\n",
    "        max_length =512  \n",
    "    )\n",
    "    \n",
    "    print(\"Test Generating Dataset\")\n",
    "    test = tf.data.Dataset.from_tensor_slices((test_embeddings))\n",
    "    test = (\n",
    "                test\n",
    "                .map(test_map_function, num_parallel_calls= AUTO)\n",
    "                .batch(24)\n",
    "                .prefetch(AUTO)\n",
    "            )\n",
    "    \n",
    "    #Clearing backend session\n",
    "    K.clear_session()\n",
    "    print(\"Backend Cleared\")\n",
    "\n",
    "    print(\"Model Creation\")\n",
    "    with strategy.scope():\n",
    "        model = create_model()\n",
    "        model.load_weights(f'../input/roberta-essay-feedback/roberta{fold}_weights.h5')\n",
    "\n",
    "    print(\"prediction on test data\")\n",
    "    preds = model.predict(test , verbose = 1)\n",
    "    preds_list.append(preds)\n",
    "    \n",
    "    del model, X_test, test , test_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "31c65733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:54:41.996390Z",
     "iopub.status.busy": "2022-08-10T04:54:41.995867Z",
     "iopub.status.idle": "2022-08-10T04:54:42.003143Z",
     "shell.execute_reply": "2022-08-10T04:54:42.002193Z"
    },
    "papermill": {
     "duration": 0.019692,
     "end_time": "2022-08-10T04:54:42.005305",
     "exception": false,
     "start_time": "2022-08-10T04:54:41.985613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4265421 , 0.5348702 , 0.03858773],\n",
       "       [0.52945906, 0.44388467, 0.02665626],\n",
       "       [0.43301445, 0.5315902 , 0.03539534],\n",
       "       [0.44010103, 0.5229849 , 0.03691405],\n",
       "       [0.44322604, 0.51865023, 0.03812374],\n",
       "       [0.42284942, 0.54812944, 0.02902113],\n",
       "       [0.3497251 , 0.61841923, 0.03185569],\n",
       "       [0.41266453, 0.54774857, 0.03958687],\n",
       "       [0.33842966, 0.6246992 , 0.03687121],\n",
       "       [0.47892803, 0.48834836, 0.0327236 ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = preds_list[0]+preds_list[1]+ \\\n",
    "              preds_list[2]+preds_list[3]\n",
    "predictions = (predictions / 4)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c29d95db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:54:42.023066Z",
     "iopub.status.busy": "2022-08-10T04:54:42.022604Z",
     "iopub.status.idle": "2022-08-10T04:54:42.029102Z",
     "shell.execute_reply": "2022-08-10T04:54:42.028063Z"
    },
    "papermill": {
     "duration": 0.018008,
     "end_time": "2022-08-10T04:54:42.031445",
     "exception": false,
     "start_time": "2022-08-10T04:54:42.013437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test['Adequate'] = predictions[:,0]\n",
    "df_test['Effective'] = predictions[:,1]\n",
    "df_test['Ineffective'] = predictions[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8504195",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:54:42.049598Z",
     "iopub.status.busy": "2022-08-10T04:54:42.049329Z",
     "iopub.status.idle": "2022-08-10T04:54:42.067029Z",
     "shell.execute_reply": "2022-08-10T04:54:42.065931Z"
    },
    "papermill": {
     "duration": 0.029809,
     "end_time": "2022-08-10T04:54:42.069576",
     "exception": false,
     "start_time": "2022-08-10T04:54:42.039767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>Ineffective</th>\n",
       "      <th>Adequate</th>\n",
       "      <th>Effective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a261b6e14276</td>\n",
       "      <td>0.038588</td>\n",
       "      <td>0.426542</td>\n",
       "      <td>0.534870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a88900e7dc1</td>\n",
       "      <td>0.026656</td>\n",
       "      <td>0.529459</td>\n",
       "      <td>0.443885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9790d835736b</td>\n",
       "      <td>0.035395</td>\n",
       "      <td>0.433014</td>\n",
       "      <td>0.531590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75ce6d68b67b</td>\n",
       "      <td>0.036914</td>\n",
       "      <td>0.440101</td>\n",
       "      <td>0.522985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93578d946723</td>\n",
       "      <td>0.038124</td>\n",
       "      <td>0.443226</td>\n",
       "      <td>0.518650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2e214524dbe3</td>\n",
       "      <td>0.029021</td>\n",
       "      <td>0.422849</td>\n",
       "      <td>0.548129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>84812fc2ab9f</td>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.349725</td>\n",
       "      <td>0.618419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c668ff840720</td>\n",
       "      <td>0.039587</td>\n",
       "      <td>0.412665</td>\n",
       "      <td>0.547749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>739a6d00f44a</td>\n",
       "      <td>0.036871</td>\n",
       "      <td>0.338430</td>\n",
       "      <td>0.624699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bcfae2c9a244</td>\n",
       "      <td>0.032724</td>\n",
       "      <td>0.478928</td>\n",
       "      <td>0.488348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id  Ineffective  Adequate  Effective\n",
       "0  a261b6e14276     0.038588  0.426542   0.534870\n",
       "1  5a88900e7dc1     0.026656  0.529459   0.443885\n",
       "2  9790d835736b     0.035395  0.433014   0.531590\n",
       "3  75ce6d68b67b     0.036914  0.440101   0.522985\n",
       "4  93578d946723     0.038124  0.443226   0.518650\n",
       "5  2e214524dbe3     0.029021  0.422849   0.548129\n",
       "6  84812fc2ab9f     0.031856  0.349725   0.618419\n",
       "7  c668ff840720     0.039587  0.412665   0.547749\n",
       "8  739a6d00f44a     0.036871  0.338430   0.624699\n",
       "9  bcfae2c9a244     0.032724  0.478928   0.488348"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[submission.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41dc74d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-10T04:54:42.089020Z",
     "iopub.status.busy": "2022-08-10T04:54:42.088749Z",
     "iopub.status.idle": "2022-08-10T04:54:42.097373Z",
     "shell.execute_reply": "2022-08-10T04:54:42.096521Z"
    },
    "papermill": {
     "duration": 0.020066,
     "end_time": "2022-08-10T04:54:42.099471",
     "exception": false,
     "start_time": "2022-08-10T04:54:42.079405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test[submission.columns].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ed5b5e",
   "metadata": {
    "papermill": {
     "duration": 0.008181,
     "end_time": "2022-08-10T04:54:42.116195",
     "exception": false,
     "start_time": "2022-08-10T04:54:42.108014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 194.331461,
   "end_time": "2022-08-10T04:54:45.264028",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-10T04:51:30.932567",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
